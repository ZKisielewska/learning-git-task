{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP6vJajspCM4uDWMhaPfiqG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZKisielewska/learning-git-task/blob/master/M_12_5_Machine_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In Google Colab, write a program that will generate data for the task using two selected generators from the loaders **sklearn_datasets** group.\n",
        "\n",
        "**Recommended datasets:**\n",
        "\n",
        "- digits\n",
        "- wine classification\n",
        "- classification of irises\n",
        "- handwritten numbers (loaded with load_mnist_data)\n",
        "\n",
        "To complete:\n",
        "\n",
        "- Select a few **classifiers** (these may be those listed in this chapter).\n",
        "- **Train and calculate metrics** for each classifier, for test and training datasets (any split).\n",
        "-Draw conclusions about the performance of each classifier, does it **work well** or does it **overfit**?\n",
        "- Write down the conclusions in the form of a simple report with a verbal description - how the data was splitted, what models were used, what conclusions were drawn."
      ],
      "metadata": {
        "id": "Ht1R8xNrmgJh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9PCkY4dDl4GA"
      },
      "outputs": [],
      "source": [
        "# load selected data sets\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.datasets import load_wine\n",
        "\n",
        "# import selected clasifiers\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Load the Iris dataset**"
      ],
      "metadata": {
        "id": "KRN1itimq6AA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# save data as variable\n",
        "# calling data 'iris' we will see a dictionary with array of lists, split between 'data' and 'target' values\n",
        "iris = load_iris()"
      ],
      "metadata": {
        "id": "gjav1dmFniVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Logistic Regression**"
      ],
      "metadata": {
        "id": "59JbZJCfnxuF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# divide our data into predictors (X) and target values (y)\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# split the data, 80% in training set and 20% in test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify = y)"
      ],
      "metadata": {
        "id": "V3B0C3LQnzWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create the clasifiers\n",
        "log_clf = LogisticRegression()\n",
        "log_clf_all = LogisticRegression()\n",
        "\n",
        "print(\"fitting - training...\")\n",
        "log_clf.fit(X_train, y_train)\n",
        "\n",
        "print(\"training on whole dataset...\")\n",
        "log_clf_all.fit(X, y)\n",
        "\n",
        "print(\"predicting...\")\n",
        "y_pred = log_clf.predict(X_test)\n",
        "\n",
        "# we print the values for the first 10 predictions\n",
        "print(\"true values \", y[:10])\n",
        "print(\"predicted \", y_pred[:10])\n",
        "\n",
        "print(\"scoring...\")\n",
        "log_clf_score = log_clf.score(X_train, y_train)\n",
        "print(\"Train score = \", log_clf_score)\n",
        "\n",
        "log_clf_score = log_clf.score(X_test, y_test)\n",
        "print(\"Test score = \", log_clf_score)\n",
        "\n",
        "log_clf_score = log_clf_all.score(X, y)\n",
        "print(\"whole set score = \", log_clf_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5el_QIBoLse",
        "outputId": "f9720756-c25b-4ba5-fc30-dec8227f3ee2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fitting - training...\n",
            "training on whole dataset...\n",
            "predicting...\n",
            "true values  [0 0 0 0 0 0 0 0 0 0]\n",
            "predicted  [0 2 1 1 0 1 0 0 2 1]\n",
            "scoring...\n",
            "Train score =  0.975\n",
            "Test score =  0.9666666666666667\n",
            "whole set score =  0.9733333333333334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Decission Tree Classifier**"
      ],
      "metadata": {
        "id": "W-fEObDwoXTY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create the clasifiers\n",
        "tree_clf = DecisionTreeClassifier()\n",
        "tree_clf_all = DecisionTreeClassifier()\n",
        "\n",
        "print(\"fitting - training...\")\n",
        "tree_clf.fit(X_train, y_train)\n",
        "\n",
        "print(\"training on whole dataset...\")\n",
        "tree_clf_all.fit(X, y)\n",
        "\n",
        "print(\"predicting...\")\n",
        "y_pred = tree_clf.predict(X_test)\n",
        "\n",
        "# we print the values for the first 10 predictions\n",
        "print(\"true values \", y[:10])\n",
        "print(\"predicted \", y_pred[:10])\n",
        "\n",
        "print(\"scoring...\")\n",
        "tree_clf_score = tree_clf.score(X_train, y_train)\n",
        "print(\"Train score = \", tree_clf_score)\n",
        "\n",
        "tree_clf_score = tree_clf.score(X_test, y_test)\n",
        "print(\"Test score = \", tree_clf_score)\n",
        "\n",
        "tree_clf_score = tree_clf_all.score(X, y)\n",
        "print(\"whole set score = \", tree_clf_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KiCuuuaboRlG",
        "outputId": "57af6338-b2d8-435b-d64e-fa71e2d0db12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fitting - training...\n",
            "training on whole dataset...\n",
            "predicting...\n",
            "true values  [0 0 0 0 0 0 0 0 0 0]\n",
            "predicted  [0 2 1 1 0 1 0 0 2 1]\n",
            "scoring...\n",
            "Train score =  1.0\n",
            "Test score =  0.9333333333333333\n",
            "whole set score =  1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SVC**"
      ],
      "metadata": {
        "id": "9CLch835ofKL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create the clasifiers\n",
        "svc_clf = SVC()\n",
        "svc_clf_all = SVC()\n",
        "\n",
        "print(\"fitting - training...\")\n",
        "svc_clf.fit(X_train, y_train)\n",
        "\n",
        "print(\"training on whole dataset...\")\n",
        "svc_clf_all.fit(X, y)\n",
        "\n",
        "print(\"predicting...\")\n",
        "y_pred = svc_clf.predict(X_test)\n",
        "\n",
        "# we print the values for the first 10 predictions\n",
        "print(\"true values \", y[:10])\n",
        "print(\"predicted \", y_pred[:10])\n",
        "\n",
        "print(\"scoring...\")\n",
        "svc_clf_score = svc_clf.score(X_train, y_train)\n",
        "print(\"Train score = \", svc_clf_score)\n",
        "\n",
        "svc_clf_score = svc_clf.score(X_test, y_test)\n",
        "print(\"Test score = \", svc_clf_score)\n",
        "\n",
        "svc_clf_score = svc_clf_all.score(X, y)\n",
        "print(\"whole set score = \", svc_clf_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yIcKWQU1ojy_",
        "outputId": "c043b0df-8d30-4156-e468-cf61bbec88da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fitting - training...\n",
            "training on whole dataset...\n",
            "predicting...\n",
            "true values  [0 0 0 0 0 0 0 0 0 0]\n",
            "predicted  [0 2 1 1 0 1 0 0 2 1]\n",
            "scoring...\n",
            "Train score =  0.9833333333333333\n",
            "Test score =  0.9666666666666667\n",
            "whole set score =  0.9733333333333334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**KNeighborsClassifier**"
      ],
      "metadata": {
        "id": "Ndqnz5UAotYL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create the clasifiers\n",
        "knn_clf = KNeighborsClassifier()\n",
        "knn_clf_all = KNeighborsClassifier()\n",
        "\n",
        "print(\"fitting - training...\")\n",
        "knn_clf.fit(X_train, y_train)\n",
        "\n",
        "print(\"training on whole dataset...\")\n",
        "knn_clf_all.fit(X, y)\n",
        "\n",
        "print(\"predicting...\")\n",
        "y_pred = knn_clf.predict(X_test)\n",
        "\n",
        "# we print the values for the first 10 predictions\n",
        "print(\"true values \", y[:10])\n",
        "print(\"predicted \", y_pred[:10])\n",
        "\n",
        "print(\"scoring...\")\n",
        "knn_clf_score = knn_clf.score(X_train, y_train)\n",
        "print(\"Train score = \", knn_clf_score)\n",
        "\n",
        "knn_clf_score = knn_clf.score(X_test, y_test)\n",
        "print(\"Test score = \", knn_clf_score)\n",
        "\n",
        "knn_clf_score = knn_clf_all.score(X, y)\n",
        "print(\"whole set score = \", knn_clf_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xiLsZ6Fqou_q",
        "outputId": "e81c27e5-4e8e-448f-c8ec-625ad4a27ad4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fitting - training...\n",
            "training on whole dataset...\n",
            "predicting...\n",
            "true values  [0 0 0 0 0 0 0 0 0 0]\n",
            "predicted  [0 2 1 1 0 1 0 0 2 1]\n",
            "scoring...\n",
            "Train score =  0.9666666666666667\n",
            "Test score =  1.0\n",
            "whole set score =  0.9666666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **IRIS** dataset was used to build the **classifiers**. The dataset contains information for three classes of the IRIS plant, namely:\n",
        "\n",
        "- IRIS **Setosa**\n",
        "- IRIS **Versicolour**\n",
        "- IRIS **Virginica**\n",
        "\n",
        "with the following attributes: **sepal length, sepal width, petal length, and petal width.**\n",
        "\n",
        "We trained our model on the train set, and tested the model on the test set. We randomly selected **80%** of the data in our **training** set and **20% as test** set.\n",
        "\n",
        "We used the follow clasifiers:\n",
        "\n",
        "- **Logistic Regression**\n",
        "\n",
        "We can see that our model works well. The test and training score are about 96%.\n",
        "\n",
        "- **Decission Tree**\n",
        "\n",
        "It might seem that in the case of the DecissionTreeClassifier we are dealing with overfitting. For the training data, we have a metric of **1.0**, while for test data we have a smaller metric, which means the model does not work well.\n",
        "\n",
        "- **SVC**\n",
        "\n",
        "The train score is 98% and it is higher then test score that is 96%. It might seem that out model is overfitting.\n",
        "\n",
        "- **KNeighborsClassifier**\n",
        "This model works wevy well. Its metrics are 96% in training set and 100% in test set.\n",
        "\n"
      ],
      "metadata": {
        "id": "BB8XQhhFpesQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Load the Wine dataset**"
      ],
      "metadata": {
        "id": "WUtFF6L3vz4v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# save data as variable\n",
        "wine = load_wine()"
      ],
      "metadata": {
        "id": "MWi56eGevpgI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# divide our data into predictors (X) and target values (y)\n",
        "X = wine.data\n",
        "y = wine.target\n",
        "\n",
        "# split the data, 80% in training set and 20% in test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify = y)"
      ],
      "metadata": {
        "id": "3AMbgZlowfwg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Logistic Regression**"
      ],
      "metadata": {
        "id": "eBRogaRrwg9n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create the clasifiers\n",
        "log_clf = LogisticRegression()\n",
        "log_clf_all = LogisticRegression()\n",
        "\n",
        "print(\"fitting - training...\")\n",
        "log_clf.fit(X_train, y_train)\n",
        "\n",
        "print(\"training on whole dataset...\")\n",
        "log_clf_all.fit(X, y)\n",
        "\n",
        "print(\"predicting...\")\n",
        "y_pred = log_clf.predict(X_test)\n",
        "\n",
        "# we print the values for the first 10 predictions\n",
        "print(\"true values \", y[:10])\n",
        "print(\"predicted \", y_pred[:10])\n",
        "\n",
        "print(\"scoring...\")\n",
        "log_clf_score = log_clf.score(X_train, y_train)\n",
        "print(\"Train score = \", log_clf_score)\n",
        "\n",
        "log_clf_score = log_clf.score(X_test, y_test)\n",
        "print(\"Test score = \", log_clf_score)\n",
        "\n",
        "log_clf_score = log_clf_all.score(X, y)\n",
        "print(\"whole set score = \", log_clf_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9MLNst5Hwfht",
        "outputId": "d3a1273d-71d3-4f47-d7b6-53f09833fd29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fitting - training...\n",
            "training on whole dataset...\n",
            "predicting...\n",
            "true values  [0 0 0 0 0 0 0 0 0 0]\n",
            "predicted  [0 2 0 1 1 0 0 1 1 2]\n",
            "scoring...\n",
            "Train score =  0.9788732394366197\n",
            "Test score =  0.9722222222222222\n",
            "whole set score =  0.9662921348314607\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Decission Tree Classifier**"
      ],
      "metadata": {
        "id": "x2U8haHGw2gU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create the clasifiers\n",
        "tree_clf = DecisionTreeClassifier()\n",
        "tree_clf_all = DecisionTreeClassifier()\n",
        "\n",
        "print(\"fitting - training...\")\n",
        "tree_clf.fit(X_train, y_train)\n",
        "\n",
        "print(\"training on whole dataset...\")\n",
        "tree_clf_all.fit(X, y)\n",
        "\n",
        "print(\"predicting...\")\n",
        "y_pred = tree_clf.predict(X_test)\n",
        "\n",
        "# we print the values for the first 10 predictions\n",
        "print(\"true values \", y[:10])\n",
        "print(\"predicted \", y_pred[:10])\n",
        "\n",
        "print(\"scoring...\")\n",
        "tree_clf_score = tree_clf.score(X_train, y_train)\n",
        "print(\"Train score = \", tree_clf_score)\n",
        "\n",
        "tree_clf_score = tree_clf.score(X_test, y_test)\n",
        "print(\"Test score = \", tree_clf_score)\n",
        "\n",
        "tree_clf_score = tree_clf_all.score(X, y)\n",
        "print(\"whole set score = \", tree_clf_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSu8G--Zw7oA",
        "outputId": "cb093277-f7ac-4241-a307-d55f1e3e2df1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fitting - training...\n",
            "training on whole dataset...\n",
            "predicting...\n",
            "true values  [0 0 0 0 0 0 0 0 0 0]\n",
            "predicted  [0 1 0 0 1 0 0 1 1 2]\n",
            "scoring...\n",
            "Train score =  1.0\n",
            "Test score =  0.9166666666666666\n",
            "whole set score =  1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SVC**"
      ],
      "metadata": {
        "id": "Hj1asAJyxHNc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create the clasifiers\n",
        "svc_clf = SVC()\n",
        "svc_clf_all = SVC()\n",
        "\n",
        "print(\"fitting - training...\")\n",
        "svc_clf.fit(X_train, y_train)\n",
        "\n",
        "print(\"training on whole dataset...\")\n",
        "svc_clf_all.fit(X, y)\n",
        "\n",
        "print(\"predicting...\")\n",
        "y_pred = svc_clf.predict(X_test)\n",
        "\n",
        "# we print the values for the first 10 predictions\n",
        "print(\"true values \", y[:10])\n",
        "print(\"predicted \", y_pred[:10])\n",
        "\n",
        "print(\"scoring...\")\n",
        "svc_clf_score = svc_clf.score(X_train, y_train)\n",
        "print(\"Train score = \", svc_clf_score)\n",
        "\n",
        "svc_clf_score = svc_clf.score(X_test, y_test)\n",
        "print(\"Test score = \", svc_clf_score)\n",
        "\n",
        "svc_clf_score = svc_clf_all.score(X, y)\n",
        "print(\"whole set score = \", svc_clf_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UE22nxWCxG01",
        "outputId": "30f6b9ed-d70b-4e6e-ee1d-4d9f1115ba26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fitting - training...\n",
            "training on whole dataset...\n",
            "predicting...\n",
            "true values  [0 0 0 0 0 0 0 0 0 0]\n",
            "predicted  [0 1 0 1 1 0 0 1 1 1]\n",
            "scoring...\n",
            "Train score =  0.676056338028169\n",
            "Test score =  0.6944444444444444\n",
            "whole set score =  0.7078651685393258\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**KNeighborsClassifier**"
      ],
      "metadata": {
        "id": "r68FnW31xLi_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create the clasifiers\n",
        "knn_clf = KNeighborsClassifier()\n",
        "knn_clf_all = KNeighborsClassifier()\n",
        "\n",
        "print(\"fitting - training...\")\n",
        "knn_clf.fit(X_train, y_train)\n",
        "\n",
        "print(\"training on whole dataset...\")\n",
        "knn_clf_all.fit(X, y)\n",
        "\n",
        "print(\"predicting...\")\n",
        "y_pred = knn_clf.predict(X_test)\n",
        "\n",
        "# we print the values for the first 10 predictions\n",
        "print(\"true values \", y[:10])\n",
        "print(\"predicted \", y_pred[:10])\n",
        "\n",
        "print(\"scoring...\")\n",
        "knn_clf_score = knn_clf.score(X_train, y_train)\n",
        "print(\"Train score = \", knn_clf_score)\n",
        "\n",
        "knn_clf_score = knn_clf.score(X_test, y_test)\n",
        "print(\"Test score = \", knn_clf_score)\n",
        "\n",
        "knn_clf_score = knn_clf_all.score(X, y)\n",
        "print(\"whole set score = \", knn_clf_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12JOi1cSxQSS",
        "outputId": "0cec6198-16fb-46a7-e69a-c068075ec810"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fitting - training...\n",
            "training on whole dataset...\n",
            "predicting...\n",
            "true values  [0 0 0 0 0 0 0 0 0 0]\n",
            "predicted  [0 2 0 1 2 0 0 1 1 2]\n",
            "scoring...\n",
            "Train score =  0.7816901408450704\n",
            "Test score =  0.8055555555555556\n",
            "whole set score =  0.7865168539325843\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **WINE** dataset was used to build the **classifiers**.\n",
        "We trained our model on the train set, and tested the model on the test set. We randomly selected **80%** of the data in our **training** set and **20%** as **test** set.\n",
        "\n",
        "We used the follow clasifiers:\n",
        "\n",
        "- **Logistic Regression**\n",
        "\n",
        "We can see that our model works well. The test and training score are about 97%.\n",
        "\n",
        "- **Decission Tree**\n",
        "\n",
        "In this case we are dealing with overfitting. For the training data, we have a metric of **1.0**, while for test data we have a smaller metric, which means the model does not work well.\n",
        "\n",
        "- **SVC**\n",
        "\n",
        "The train score is 67% and it is lower then test score that is 69%. These results are quite poor and inform us that our model does not work well.\n",
        "\n",
        "- **KNeighborsClassifier**\n",
        "In this case, like with SVC we are dealing with low metrics. This model will not work well either.\n",
        "\n",
        "It seems that in both cases, for **IRIS** and **WINE** data sets the best solution is using **Logistic Regression** for modelling. The metrics are over 96% and model should well predict with this clasifier."
      ],
      "metadata": {
        "id": "NYE99YYYyjTQ"
      }
    }
  ]
}